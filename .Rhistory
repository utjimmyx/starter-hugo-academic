blogdown:::serve_site()
blogdown::build_site()
getwd()
blogdown:::serve_site()
# Create a sample data frame
df <- data.frame(W2 = c("JavaScript;Python;JavaScript;", "Java;C++;Python;JavaScript;", "Python;JavaScript;", "C++;Python;"))
# View the sample data frame
print(df)
# Apply the formula
result <- (nchar(paste(df$W2, ";")) - nchar(sub(df$W2, "JavaScript;", ""))) / nchar("JavaScript;")
# View the result
print(result)
# Create a sample data frame
df <- data.frame(W2 = c("Python;JavaScript;",
"Java;C++;Python;JavaScript;",
"Python;JavaScript;", "C++;Python;"))
# View the sample data frame
print(df)
# Apply the formula
result <- (nchar(paste(df$W2, ";"))
- nchar(sub(df$W2, "JavaScript;", ""))) / nchar("JavaScript;")
# View the result
print(result)
# Apply the formula
result <- (nchar(paste(df$W2, ";"))
- nchar(sub(df$W2, "JavaScript;", ""))) / nchar("JavaScript;")
# View the result
print(result)
# Create a data frame
df <- data.frame(W2 = c("JavaScript;Python;R", "JavaScript;C++"))
# Call the g() function
result <- g(df)
# The R code:
g <- function(df) {
(length(df$W2) - length(str_replace(df$W2, "JavaScript;", ""))) / length("JavaScript;")
}
# Apply the formula
result <- (nchar(paste(df$W2, ";"))
- nchar(sub(df$W2, "JavaScript;", ""))) / nchar("JavaScript;")
# View the result
print(result)
# Create a data frame
df <- data.frame(W2 = c("JavaScript;Python;R", "JavaScript;C++"))
# Call the g() function
result <- g(df)
setwd("C:/Users/zxu3/Documents/R")
#install.packages("readr")
library(readr)
data <- read_csv("book3.csv")
#install.packages("readr")
library(readr)
data <- read_csv("book3.csv")
View(data)
View(data)
library(readr)
df <- read_csv("book3.csv")
# Assuming your data is in a data frame named 'df' and the column is 'B2'
df <- df %>%
mutate(result = case_when(
B2 == "great" ~ 4,
B2 == "good" ~ 3,
B2 == "ok" ~ 2,
B2 == "bad" ~ 1,
TRUE ~ NA_real_  # Default value if none of the conditions are met
))
df <- read_csv("book3.csv")
library(dplyr)
# Assuming your data is in a data frame named 'df' and the column is 'B2'
df  %>%
mutate(result = case_when(
evals == "great" ~ 4,
evals == "good" ~ 3,
evals == "ok" ~ 2,
evals == "bad" ~ 1,
TRUE ~ NA_real_  # Default value if none of the conditions are met
))
# Assuming your data is in a data frame named 'df' and the column is 'B2'
df <- df %>%
mutate(result = case_when(
evals == "great" ~ 4,
evals == "good" ~ 3,
evals == "ok" ~ 2,
evals == "bad" ~ 1,
TRUE ~ NA_real_  # Default value if none of the conditions are met
))
df
# Assuming your data is in a data frame named 'df' and the column is 'B2'
df$result <- ifelse(df$evals == "great", 4,
ifelse(df$B2 == "good", 3,
ifelse(df$B2 == "ok", 2,
ifelse(df$B2 == "bad", 1, NA)
)
)
)
# Assuming your data is in a data frame named 'df' and the column is 'B2'
df$result <- ifelse(df$evals == "great", 4,
ifelse(df$evals == "good", 3,
ifelse(df$evals == "ok", 2,
ifelse(df$evals == "bad", 1, NA)
)
)
)
df
callprice <- function(p0, K, T, r, sigma, N){
optionPayOffs=vector();
dt = 1/260              # Number of periods per year
mu = r                  # risk neutral pricing
muInt = mu
sigmaInt = sigma*sqrt(dt) # Convert to daily
Periods = T             # Since T is in days
for(i in 1:N){
returns=rnorm(Periods,muInt,sigmaInt)
prices=p0*cumprod(returns+1)
optionPayOffs[i]=max(prices[Periods]-K,0)
}
optPrice=mean(optionPayOffs)/(1+r)^T
}
cp1 <- callprice(757.31, 755, 119, 0, 0.05, 10000)
cp1
cp2 <- callprice(757.31, 755, 119, 0, 0.1, 10000)
cp2
library(rvest)
library(tidyverse)
zom <- read_html("https://www.zomato.com/bangalore/restaurants?buffet=1")
#install Packages
install.packages("rvest") #https://cran.r-project.org/web/packages/rvest/rvest.pdf
install.packages("ggplot2")
#Loading the rvest package
library('rvest')
library('ggplot2')
#----------------------------------------------------------------------------------------------------------------
#Specifying the url for desired website to be scrapped
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
#Reading the HTML code from the website
webpage <- read_html(url)
#----------------------------------------------------------------------------------------------------------------
#scraping the following data
#Rank , #Title, #Description , #Runtime, #Genre, #Rating, #Votes, #Gross_Earning_in_Mil, #Director
#Actor, #Metascore
#---------------------------------------------------------------------------------------------------------------
#Step 1: RANK
#use Selector Gadget : http://selectorgadget.com
#Seelct Rank filed and get(Copy) HTML CSS Selector; Make sure all are selected or necesary films rank got selected
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
#Let's have a look at the rankings
head(rank_data)
tail(rank_data)
#Data-Preprocessing: Converting rankings to numerical
rank_data<-as.numeric(rank_data)
#Let's have another look at the rankings
head(rank_data)
tail(rank_data)
#---------------------------------------------------------------------------------------------------------------
#Step 2: Title
title_data_html <- html_nodes(webpage,'.lister-item-header a')
title_data <- html_text(title_data_html)
head(title_data)
tail(title_data)
#---------------------------------------------------------------------------------------------------------------
#Step 3: Description
description_data_html <- html_nodes(webpage,'.ratings-bar+ .text-muted')
description_data <- html_text(description_data_html)
head(description_data)
tail(description_data)
#Data-Preprocessing: removing '\n'
description_data<-gsub("\n","",description_data)
#Let's have another look at the description data
head(description_data)
#---------------------------------------------------------------------------------------------------------------
#Step 4: Runtime
runtime_data_html <- html_nodes(webpage,'.text-muted .runtime')
runtime_data <- html_text(runtime_data_html)
head(runtime_data)
tail(runtime_data)
#Data-Preprocessing: removing mins and converting it to numerical
runtime_data<-gsub(" min","",runtime_data)
runtime_data<-as.numeric(runtime_data)
#Let's have another look at the runtime data
head(runtime_data)
tail(runtime_data)
#---------------------------------------------------------------------------------------------------------------
#Step 5: Gener
genre_data_html <- html_nodes(webpage,'.genre')
genre_data <- html_text(genre_data_html)
head(genre_data)
tail(genre_data)
#Data-Preprocessing: removing \n
genre_data<-gsub("\n","",genre_data)
#Data-Preprocessing: removing excess spaces
genre_data<-gsub(" ","",genre_data)
#taking only the first genre of each movie
genre_data<-gsub(",.*","",genre_data)
#Convering each genre from text to factor
genre_data<-as.factor(genre_data)
#Let's have another look at the genre data
head(genre_data)
tail(genre_data)
install.packages("rvest")
install.packages("rvest")
#Loading the rvest package
library('rvest')
library('ggplot2')
#Specifying the url for desired website to be scrapped
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
#Reading the HTML code from the website
webpage <- read_html(url)
url <- 'https://www.imdb.com/search/title/?title_type=feature&release_date=2022-01-01,2023-01-01&count=100'
webpage <- read_html(url)
url <- 'https://www.imdb.com/search/title/?title_type=feature&release_date=2023-01-01,2023-11-20&count=100'
#Reading the HTML code from the website
webpage <- read_html(url)
View(webpage)
View(webpage)
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
url <- 'https://www.imdb.com/search/title/?title_type=feature&release_date=2023-01-01,2023-11-20&count=100'
#Reading the HTML code from the website
webpage <- read_html(url)
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
rank_data <- html_text(rank_data_html)
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
webpage <- read_html(url)
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
webpage <- read_html(url)
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
#Let's have a look at the rankings
head(rank_data)
tail(rank_data)
#Data-Preprocessing: Converting rankings to numerical
rank_data<-as.numeric(rank_data)
#Let's have another look at the rankings
head(rank_data)
tail(rank_data)
#---------------------------------------------------------------------------------------------------------------
#Step 2: Title
title_data_html <- html_nodes(webpage,'.lister-item-header a')
title_data <- html_text(title_data_html)
head(title_data)
tail(title_data)
#---------------------------------------------------------------------------------------------------------------
#Step 3: Description
description_data_html <- html_nodes(webpage,'.ratings-bar+ .text-muted')
description_data <- html_text(description_data_html)
head(description_data)
tail(description_data)
#Data-Preprocessing: removing '\n'
description_data<-gsub("\n","",description_data)
#Let's have another look at the description data
head(description_data)
#---------------------------------------------------------------------------------------------------------------
#Step 4: Runtime
runtime_data_html <- html_nodes(webpage,'.text-muted .runtime')
runtime_data <- html_text(runtime_data_html)
head(runtime_data)
tail(runtime_data)
#Data-Preprocessing: removing mins and converting it to numerical
runtime_data<-gsub(" min","",runtime_data)
runtime_data<-as.numeric(runtime_data)
#Let's have another look at the runtime data
head(runtime_data)
tail(runtime_data)
#---------------------------------------------------------------------------------------------------------------
#Step 5: Gener
genre_data_html <- html_nodes(webpage,'.genre')
genre_data <- html_text(genre_data_html)
head(genre_data)
tail(genre_data)
View(webpage)
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
#Reading the HTML code from the website
webpage <- read_html(url)
#scraping the following data
#Rank , #Title, #Description , #Runtime, #Genre, #Rating, #Votes, #Gross_Earning_in_Mil, #Director
#Actor, #Metascore
#---------------------------------------------------------------------------------------------------------------
#Step 1: RANK
#use Selector Gadget : http://selectorgadget.com
#Seelct Rank filed and get(Copy) HTML CSS Selector; Make sure all are selected or necesary films rank got selected
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'.text-primary')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
#Let's have a look at the rankings
head(rank_data)
tail(rank_data)
#Let's have a look at the rankings
head(rank_data)
tail(rank_data)
#Loading the rvest package
library('rvest')
library('ggplot2')
link<- ("https://www.imdb.com/search/title/?genres=action&sort=user_rating,desc&title_type=feature&num_votes=25000,&pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=f11158cc-b50b-4c4d-b0a2-40b32863395b&pf_rd_r=GMJM46PTFY8D7B4S5199&pf_rd_s=right-6&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_gnr_1")
page<- read_html(link)
## Let us extract the name, year, genre, length,user rating,director
## and synopsis of the first 50 movies of the 1st page.
name<-page%>%html_nodes(".lister-item-header a")%>%html_text()
year<-page%>%html_nodes(".text-muted.unbold")%>%html_text()
genre<-page%>%html_nodes(".genre")%>%html_text()
length<-page%>%html_nodes(".runtime")%>%html_text()
user_rating<-page%>%html_nodes(".ratings-imdb-rating strong")%>%html_text()
director<-page%>%html_nodes(".text-muted+ p a:nth-child(1)")%>%html_text()
synopsis<-page%>%html_nodes(".ratings-bar+ .text-muted")%>%html_text()
## We will convert our data's to a data frame
movies<-data.frame(name, year, genre, length,user_rating,director,synopsis)
head(movies)
link<- ("https://www.imdb.com/search/title/?title_type=feature&release_date=2023-01-01,2023-11-20&count=100")
page<- read_html(link)
## Let us extract the name, year, genre, length,user rating,director
## and synopsis of the first 50 movies of the 1st page.
name<-page%>%html_nodes(".lister-item-header a")%>%html_text()
year<-page%>%html_nodes(".text-muted.unbold")%>%html_text()
genre<-page%>%html_nodes(".genre")%>%html_text()
length<-page%>%html_nodes(".runtime")%>%html_text()
user_rating<-page%>%html_nodes(".ratings-imdb-rating strong")%>%html_text()
director<-page%>%html_nodes(".text-muted+ p a:nth-child(1)")%>%html_text()
synopsis<-page%>%html_nodes(".ratings-bar+ .text-muted")%>%html_text()
## We will convert our data's to a data frame
movies<-data.frame(name, year, genre, length,user_rating,director,synopsis)
head(movies)
link<- ("https://www.imdb.com/search/title/?genres=action&sort=user_rating,desc&title_type=feature&num_votes=25000,&pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=f11158cc-b50b-4c4d-b0a2-40b32863395b&pf_rd_r=GMJM46PTFY8D7B4S5199&pf_rd_s=right-6&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_gnr_1")
page<- read_html(link)
## Let us extract the name, year, genre, length,user rating,director
## and synopsis of the first 50 movies of the 1st page.
name<-page%>%html_nodes(".lister-item-header a")%>%html_text()
year<-page%>%html_nodes(".text-muted.unbold")%>%html_text()
genre<-page%>%html_nodes(".genre")%>%html_text()
length<-page%>%html_nodes(".runtime")%>%html_text()
user_rating<-page%>%html_nodes(".ratings-imdb-rating strong")%>%html_text()
director<-page%>%html_nodes(".text-muted+ p a:nth-child(1)")%>%html_text()
synopsis<-page%>%html_nodes(".ratings-bar+ .text-muted")%>%html_text()
## We will convert our data's to a data frame
movies<-data.frame(name, year, genre, length,user_rating,director,synopsis)
head(movies)
url <- "https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/"
html <- read_html(url)
table <- html |>
html_element("table") |>
html_table()
table
table <- html |>
html_element("table") |>
html_table()
table
ratings <- table |>
select(
rank_title_year = `Rank & Title`,
rating = `IMDb Rating`
) |>
mutate(
rank_title_year = str_replace_all(rank_title_year, "\n +", " ")
) |>
separate_wider_regex(
rank_title_year,
patterns = c(
rank = "\\d+", "\\. ",
title = ".+", " +\\(",
year = "\\d+", "\\)"
)
)
ratings
html |>
html_elements("td strong") |>
head() |>
html_attr("title")
html |>
html_elements("td strong") |>
head() |>
html_attr("title")
ratings |>
mutate(
rating_n = html |> html_elements("td strong") |> html_attr("title")
) |>
separate_wider_regex(
rating_n,
patterns = c(
"[0-9.]+ based on ",
number = "[0-9,]+",
" user ratings"
)
) |>
mutate(
number = parse_number(number)
)
head(ratings)
View(ratings)
View(ratings)
link<- ("https://www.imdb.com/search/title/?title_type=feature&release_date=2023-01-01,2023-11-20&count=100")
html <- read_html(link)
table <- html |>
html_element("table") |>
html_table()
page <- read_html(link)
##https://www.kaggle.com/code/joselitochavez/web-scraping-imdb-com-using-r
## Let us extract the name, year, genre, length,user rating,director
## and synopsis of the first 50 movies of the 1st page.
name<-page%>%html_nodes(".lister-item-header a")%>%html_text()
year<-page%>%html_nodes(".text-muted.unbold")%>%html_text()
genre<-page%>%html_nodes(".genre")%>%html_text()
length<-page%>%html_nodes(".runtime")%>%html_text()
user_rating<-page%>%html_nodes(".ratings-imdb-rating strong")%>%html_text()
director<-page%>%html_nodes(".text-muted+ p a:nth-child(1)")%>%html_text()
synopsis<-page%>%html_nodes(".ratings-bar+ .text-muted")%>%html_text()
# load libraries
library(RSelenium)
install.packages("RSelenium")
# load libraries
library(RSelenium)
library(rvest)
library(magrittr)
library(readr)
# define target url
url <- "https://www.ratemyprofessors.com/school/158"
rD <- rsDriver(browser="firefox", port=4550L, chromever = NULL)
# open the remote driver-------------------------------------------------------
# If it doesn't open automatically:
remDr$open()
urls <- c("https://www.imdb.com/search/title?release_date=2021-01-01,2021-12-31&count=100&start=101&ref_=adv_prv",
"https://www.imdb.com/search/title?release_date=2022-01-01,2022-12-31&count=100&start=201&ref_=adv_nxt")`
results_list <- list()
for(.page in seq_along(urls)){
webpage <- read_html(urls[[.page]])
titlehtml <- html_nodes(webpage,'.lister-item-header a')
title <- html_text(titlehtml)
runtimehtml <- html_nodes(webpage,'.text-muted .runtime')
runtime <- html_text(runtimehtml)
runtime <- gsub(" min","",runtime)
results_list[[.page]] <- data.frame(title = title,
runtime = as.numeric(runtime)
)
}
final_results <- plyr::ldply(results_list)
final_results
)
)
urls <- c("https://www.imdb.com/search/title?release_date=2021-01-01,2021-12-31&count=100&start=101&ref_=adv_prv",
"https://www.imdb.com/search/title?release_date=2022-01-01,2022-12-31&count=100&start=201&ref_=adv_nxt")`
urls <- c("https://www.imdb.com/search/title?release_date=2021-01-01,2021-12-31&count=100&start=101&ref_=adv_prv",
"https://www.imdb.com/search/title?release_date=2022-01-01,2022-12-31&count=100&start=201&ref_=adv_nxt")
results_list <- list()
results_list
for(.page in seq_along(urls)){
webpage <- read_html(urls[[.page]])
titlehtml <- html_nodes(webpage,'.lister-item-header a')
title <- html_text(titlehtml)
runtimehtml <- html_nodes(webpage,'.text-muted .runtime')
runtime <- html_text(runtimehtml)
runtime <- gsub(" min","",runtime)
results_list[[.page]] <- data.frame(title = title,
runtime = as.numeric(runtime)
)
}
final_results <- plyr::ldply(results_list)
View(final_results)
View(final_results)
q()
